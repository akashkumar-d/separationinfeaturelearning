{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "061ac436-51ef-49be-a528-b279ab061540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from experiment import run_optimizer_experiment\n",
    "from muon import MuonWithAuxAdam, Muon, SingleDeviceMuon, SingleDeviceMuonWithAuxAdam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e482365-2b78-4dbf-8c61-c81def54cc4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class ThreeLayerNet(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "#         super(ThreeLayerNet, self).__init__()\n",
    "#         # Define three linear layers without biases.\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1, bias=False)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2, bias=False)\n",
    "#         self.fc3 = nn.Linear(hidden_size2, output_size, bias=False)\n",
    "#         self.d = input_size\n",
    "#         self.h1 = hidden_size1\n",
    "#         self.h2 = hidden_size2\n",
    "        \n",
    "#         self.body = nn.Sequential(*[self.fc1, nn.ReLU(),\n",
    "#                                   self.fc2, nn.ReLU(),])\n",
    "#         self.head =  self.fc3\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.head(self.body(x))\n",
    "    \n",
    "#     def initialize(self):\n",
    "#         self.fc1.weight.data.normal_(0, 1)\n",
    "#         self.fc2.weight.data.normal_(0, 1)\n",
    "#         self.fc3.weight.data.normal_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ceabf31-3542-4007-b833-573b5fc608c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam, Adagrad, SGD, RMSprop\n",
    "from muon import MuonWithAuxAdam, Muon, SingleDeviceMuon, SingleDeviceMuonWithAuxAdam\n",
    "from torch_optimizer import Shampoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a771c2f1-986f-4cd1-ada6-d665036fec92",
   "metadata": {},
   "source": [
    "| Optimizer       | Learning rates (`lr`)          | Batch sizes       | Extras           |\n",
    "| --------------- | ------------------------------ | ----------------- | ---------------- |\n",
    "| **SGD**         | 0.1  • 0.01  • 0.001           | 32  • 128  • 1024 | `momentum = 0.9` |\n",
    "| **Adam**        | 0.1  • 0.01  • PyTorch default | 32  • 128  • 1024 | —                |\n",
    "| **Muon + Adam** | 0.01  • Default                | 32  • 128  • 1024 | —                |\n",
    "| **Muon**        | 0.01  • Default                | 32  • 128  • 1024 | —                |\n",
    "| **Shampoo**     | 0.1  • 0.01  • 0.001           | 32  • 128  • 1024 | —                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f02395-19b9-4987-b112-806f9b9cff77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [0.01]\n",
    "# batch_sizes = [512, ]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         N = 2000\n",
    "#         # if lr == 0.001:\n",
    "#             # N = 300\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = SGD,\n",
    "#             optimizer_kwargs = {'lr':lr},\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = False,\n",
    "#             output_dir = 'one_index_exp',\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148c4f87-469b-4efc-9d92-1564e2361d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [0.1, 0.01, 0.001]\n",
    "# batch_sizes = [512, ]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         N = 3000\n",
    "#         if lr == 0.001:\n",
    "#             N = 10_000\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = SGD,\n",
    "#             optimizer_kwargs = {'lr':lr},\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab072cec-8c7f-4440-84b1-45d531ed5ae9",
   "metadata": {},
   "source": [
    "# SGD experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0852eb9-c6a1-48af-8f7b-e47ece0a23d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder compare_sgd_vs_muon_2layers/SGD_20251030_160156\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/SGD_20251030_160156/config.txt\n",
      "[INFO] Starting 3 repetitions of SGD\n",
      "***************\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/SGD_20251030_160156\n",
      "Created folder compare_sgd_vs_muon_2layers/SGD_20251030_162250\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/SGD_20251030_162250/config.txt\n",
      "[INFO] Starting 3 repetitions of SGD\n",
      "***************\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/SGD_20251030_164125\n"
     ]
    }
   ],
   "source": [
    "# lrs = [0.1, 0.01, 0.001]\n",
    "# batch_sizes = [128, 512, 1024]\n",
    "lrs = [0.01]\n",
    "batch_sizes = [16, 32, 64, 128, 256, 512]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        N = 2000\n",
    "        if lr == 0.001:\n",
    "            N = 10_000\n",
    "        results = run_optimizer_experiment(\n",
    "            optimizer_cls   = SGD,\n",
    "            optimizer_kwargs = {'lr':lr},\n",
    "            batch_size      = bs,\n",
    "            num_repeats     = 3,\n",
    "            num_epochs      = N,\n",
    "            early_stop = False, \n",
    "            output_dir = \"compare_sgd_vs_muon_2layers\",\n",
    "            two_layer_net  =True,\n",
    "            # link_function = lambda x: x[:,0] + x[:,1]\n",
    "        )\n",
    "\n",
    "# # lrs = [0.001]\n",
    "# # batch_sizes = [ 1024]\n",
    "\n",
    "# # for lr in lrs:\n",
    "# #     for bs in batch_sizes:\n",
    "# #         N = 6000\n",
    "# #         if lr == 0.001:\n",
    "# #             N = 30_000\n",
    "# #         results = run_optimizer_experiment(\n",
    "# #             optimizer_cls   = SGD,\n",
    "# #             optimizer_kwargs = {'lr':lr},\n",
    "# #             batch_size      = bs,\n",
    "# #             num_repeats     = 5,\n",
    "# #             num_epochs      = N,\n",
    "# #             early_stop = True\n",
    "# #         )\n",
    "        \n",
    "# # lrs = [0.1, 0.01, 0.001, ]\n",
    "# # batch_sizes = [128, 1024]\n",
    "\n",
    "# # for lr in lrs:\n",
    "# #     for bs in batch_sizes:\n",
    "# #         N = 5000\n",
    "# #         if lr == 0.001:\n",
    "# #             N = 20_000\n",
    "\n",
    "# #         results = run_optimizer_experiment(\n",
    "# #             optimizer_cls   = SGD,\n",
    "# #             optimizer_kwargs = {'lr':lr, 'momentum':0.9},\n",
    "# #             batch_size      = bs,\n",
    "# #             num_repeats     = 5,\n",
    "# #             num_epochs      = N,\n",
    "# #             early_stop = True\n",
    "# #         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530c8f0-681d-4f11-9959-efa8a5f104d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder compare_sgd_vs_muon_2layers/Adam_20251030_212035\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/Adam_20251030_212035/config.txt\n",
      "[INFO] Starting 3 repetitions of Adam\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/Adam_20251030_212035\n",
      "Created folder compare_sgd_vs_muon_2layers/Adam_20251030_212209\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/Adam_20251030_212209/config.txt\n",
      "[INFO] Starting 3 repetitions of Adam\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/Adam_20251030_212209\n",
      "Created folder compare_sgd_vs_muon_2layers/Adam_20251030_212415\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/Adam_20251030_212415/config.txt\n",
      "[INFO] Starting 3 repetitions of Adam\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/Adam_20251030_212415\n",
      "Created folder compare_sgd_vs_muon_2layers/Adam_20251030_212725\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/Adam_20251030_212725/config.txt\n",
      "[INFO] Starting 3 repetitions of Adam\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.0, 0.9999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "{'lr': 0.01, 'betas': (0.0, 0.9999)}\n",
      "***************\n",
      "  Epoch 1911/2000 ( 95.5%)\r"
     ]
    }
   ],
   "source": [
    "# lrs = [0.1, 0.01, 0.001]\n",
    "# batch_sizes = [128, 512, 1024]\n",
    "lrs = [0.01]\n",
    "batch_sizes = [16, 32, 64, 128, 256, 512][::-1]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        N = 2000\n",
    "        if lr == 0.001:\n",
    "            N = 10_000\n",
    "        results = run_optimizer_experiment(\n",
    "            optimizer_cls   = Adam,\n",
    "            optimizer_kwargs = {'lr':lr, 'betas': (0.0, .9999)},\n",
    "            batch_size      = bs,\n",
    "            num_repeats     = 3,\n",
    "            num_epochs      = N,\n",
    "            early_stop = False, \n",
    "            output_dir = \"compare_sgd_vs_muon_2layers\",\n",
    "            two_layer_net  =True,\n",
    "            # link_function = lambda x: x[:,0] + x[:,1]\n",
    "        )\n",
    "\n",
    "# # lrs = [0.001]\n",
    "# # batch_sizes = [ 1024]\n",
    "\n",
    "# # for lr in lrs:\n",
    "# #     for bs in batch_sizes:\n",
    "# #         N = 6000\n",
    "# #         if lr == 0.001:\n",
    "# #             N = 30_000\n",
    "# #         results = run_optimizer_experiment(\n",
    "# #             optimizer_cls   = SGD,\n",
    "# #             optimizer_kwargs = {'lr':lr},\n",
    "# #             batch_size      = bs,\n",
    "# #             num_repeats     = 5,\n",
    "# #             num_epochs      = N,\n",
    "# #             early_stop = True\n",
    "# #         )\n",
    "        \n",
    "# # lrs = [0.1, 0.01, 0.001, ]\n",
    "# # batch_sizes = [128, 1024]\n",
    "\n",
    "# # for lr in lrs:\n",
    "# #     for bs in batch_sizes:\n",
    "# #         N = 5000\n",
    "# #         if lr == 0.001:\n",
    "# #             N = 20_000\n",
    "\n",
    "# #         results = run_optimizer_experiment(\n",
    "# #             optimizer_cls   = SGD,\n",
    "# #             optimizer_kwargs = {'lr':lr, 'momentum':0.9},\n",
    "# #             batch_size      = bs,\n",
    "# #             num_repeats     = 5,\n",
    "# #             num_epochs      = N,\n",
    "# #             early_stop = True\n",
    "# #         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf5681-72ea-4794-9688-37cbe5b75e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_182441\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_182441/config.txt\n",
      "[INFO] Starting 3 repetitions of SingleDeviceMuon\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_182441\n",
      "Created folder compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_183822\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_183822/config.txt\n",
      "[INFO] Starting 3 repetitions of SingleDeviceMuon\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_183822\n",
      "Created folder compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_184526\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_184526/config.txt\n",
      "[INFO] Starting 3 repetitions of SingleDeviceMuon\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_184526\n",
      "Created folder compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_184930\n",
      "[INFO] Writing config to compare_sgd_vs_muon_2layers/SingleDeviceMuon_20251030_184930/config.txt\n",
      "[INFO] Starting 3 repetitions of SingleDeviceMuon\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "  Epoch 1221/2000 ( 61.1%)\r"
     ]
    }
   ],
   "source": [
    "lrs = [0.01]\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        opt_kwargs = {}\n",
    "        N = 2000\n",
    "        # opt_kwargs['betas'] = (0.0, 0.0)\n",
    "        opt_kwargs['weight_decay'] = 0.0\n",
    "        opt_kwargs['momentum'] = 0.0\n",
    "        opt_kwargs['weight_decay'] = 0.0\n",
    "\n",
    "        if lr is not None:\n",
    "            opt_kwargs['lr'] = lr\n",
    "        # elif lr == 0.001:\n",
    "        #     N = 300\n",
    "\n",
    "        results = run_optimizer_experiment(\n",
    "            optimizer_cls   = SingleDeviceMuon,\n",
    "            optimizer_kwargs = opt_kwargs,\n",
    "            batch_size      = bs,\n",
    "            num_repeats     = 3,\n",
    "            num_epochs      = N,\n",
    "            early_stop = False,\n",
    "            output_dir = \"compare_sgd_vs_muon_2layers\",\n",
    "            two_layer_net  =True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db48851-55f6-4104-b48a-1868c95a716f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec2f06-8dd3-41f9-a39a-459d30de138f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [0.001]\n",
    "batch_sizes = [512, ]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        opt_kwargs = {}\n",
    "        N = 1000\n",
    "        if lr is not None:\n",
    "            opt_kwargs['lr'] = lr\n",
    "        # elif lr == 0.001:\n",
    "            # N = 10_000\n",
    "        results = run_optimizer_experiment(\n",
    "            optimizer_cls   = Adam,\n",
    "            optimizer_kwargs = opt_kwargs,\n",
    "            batch_size      = bs,\n",
    "            num_repeats     = 5,\n",
    "            num_epochs      = N,\n",
    "            early_stop = False,\n",
    "            output_dir = \"one_index_exp\"\n",
    "        )\n",
    "        # display(results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941a79a-0f89-4020-8266-e4ee1846fd6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [0.1, 0.01, 0.001]\n",
    "# batch_sizes = [128, 512, 1024]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "#         N = 5_000\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "#         elif lr == 0.001:\n",
    "#             N = 10_000\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = AdamW,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True,\n",
    "#             output_dir = \"two_indices_exp\"\n",
    "#         )\n",
    "#         # display(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45cb0b-b582-4c9e-8c98-5a6803395031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [0.01]\n",
    "# batch_sizes = [1024]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "#         N = 5_000\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "#         elif lr == 0.001:\n",
    "#             N = 10_000\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = Adam,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True\n",
    "#         )\n",
    "#         # display(results[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c82cb6-c1a1-4cc5-848a-e73d9c9ee23e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [ 0.0001 ]\n",
    "# batch_sizes = [128]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "#         N = 5_000\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "#         elif lr <= 0.001:\n",
    "#             N = 10_000\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = Adam,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True\n",
    "#         )\n",
    "#         # display(results[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ced50a-2f64-4acf-9ad7-75be4435a5a8",
   "metadata": {},
   "source": [
    "# Muon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5feb8304-57f4-4e4c-b0c6-e2cc61f5e3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleDeviceMuon (\n",
       "Parameter Group 0\n",
       "    lr: 0.02\n",
       "    momentum: 0.0\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ThreeLayerNet(16, 128, 128, 1)\n",
    "optimizer = SingleDeviceMuon( net.parameters(), momentum = 0., weight_decay=0.)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4885cda9-e5f5-44ab-abd7-12fb592d29ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder 2layer_exp/SingleDeviceMuon_20251029_182721\n",
      "[INFO] Writing config to 2layer_exp/SingleDeviceMuon_20251029_182721/config.txt\n",
      "[INFO] Starting 5 repetitions of SingleDeviceMuon\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 1\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 2\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 3\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 4\n",
      "***************\n",
      "SingleDeviceMuon (\n",
      "Parameter Group 0\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: True\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    betas: (0.0, 0.0)\n",
      "    lr: 0.01\n",
      "    momentum: 0.0\n",
      "    use_muon: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "{'weight_decay': 0.0, 'momentum': 0.0, 'lr': 0.01}\n",
      "***************\n",
      "[INFO] Saving .npy for repeat 5\n",
      "[INFO] Aggregating results and plotting\n",
      "[INFO] Experiment complete. All outputs in: 2layer_exp/SingleDeviceMuon_20251029_182721\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.01, ]\n",
    "batch_sizes = [32, ]\n",
    "# lrs = [0.1]\n",
    "# batch_sizes = [128]\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        opt_kwargs = {}\n",
    "        N = 100\n",
    "        # opt_kwargs['betas'] = (0.0, 0.0)\n",
    "        opt_kwargs['weight_decay'] = 0.0\n",
    "        opt_kwargs['momentum'] = 0.0\n",
    "        opt_kwargs['weight_decay'] = 0.0\n",
    "\n",
    "        if lr is not None:\n",
    "            opt_kwargs['lr'] = lr\n",
    "        # elif lr == 0.001:\n",
    "        #     N = 300\n",
    "\n",
    "        results = run_optimizer_experiment(\n",
    "            optimizer_cls   = SingleDeviceMuon,\n",
    "            optimizer_kwargs = opt_kwargs,\n",
    "            batch_size      = bs,\n",
    "            num_repeats     = 5,\n",
    "            num_epochs      = N,\n",
    "            early_stop = False,\n",
    "            output_dir = \"2layer_exp\",\n",
    "            two_layer_net = True,\n",
    "        )\n",
    "        \n",
    "# lrs = [0.1, 0.01 ]\n",
    "# # batch_sizes = [ 128, 1024]\n",
    "# batch_sizes = [128]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "#         N = 3_000\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "#         elif lr == 0.001:\n",
    "#             N = 10_000\n",
    "\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = SingleDeviceMuon,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True\n",
    "#         )Created folder one_index_exp/SingleDeviceMuon_20251007_033424"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660088f-4890-4864-beb6-6e05ff7e5fd1",
   "metadata": {},
   "source": [
    "# MuonWithAuxAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f9d125-1aaa-48f5-b0ff-ef74b72d0978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [0.1, 0.01, 0.001]\n",
    "# batch_sizes = [128, 512, 1024]\n",
    "\n",
    "# # batch_sizes = [1024]\n",
    "\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "        \n",
    "#         # N = 3000\n",
    "#         N = 10_000\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "#         elif lr == 0.001:\n",
    "#             N = 10_000\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = SingleDeviceMuonWithAuxAdam,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True,\n",
    "#             output_dir = \"two_indices_exp\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b89d3-7b61-4fdb-a343-23f2ba93a506",
   "metadata": {},
   "source": [
    "# Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f985ee-b687-4ca8-a162-0aeae758a9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [0.1, 0.01, 0.001 ]\n",
    "# batch_sizes = [ 128, 512, 1024]\n",
    "# # batch_sizes = [1024]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "#         N = 7000\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "#         elif lr == 0.001:\n",
    "#             N = 10_000\n",
    "\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = Adagrad,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = N,\n",
    "#             early_stop = True,\n",
    "#             output_dir = \"two_indices_exp\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0cd3c25-826c-4038-8686-0c1e3cfea984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lrs = [None, 0.01, ]\n",
    "# batch_sizes = [128, 1024]\n",
    "\n",
    "# for lr in lrs:\n",
    "#     for bs in batch_sizes:\n",
    "#         opt_kwargs = {}\n",
    "#         if lr is not None:\n",
    "#             opt_kwargs['lr'] = lr\n",
    "\n",
    "#         results = run_optimizer_experiment(\n",
    "#             optimizer_cls   = Shampoo,\n",
    "#             optimizer_kwargs = opt_kwargs,\n",
    "#             batch_size      = bs,\n",
    "#             num_repeats     = 5,\n",
    "#             num_epochs      = 10_000,\n",
    "#             early_stop = True\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297affd-bade-40af-b83d-b10956f5954d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SGD weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345fb675-102d-480b-ad14-c471fa243aa2",
   "metadata": {},
   "source": [
    "# Shampoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95e0eb9c-834e-4400-987a-b82e5e6a033e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, Iterable, Optional, Tuple, Union\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "Params = Union[Iterable[Tensor], Iterable[Dict[str, Any]]]\n",
    "\n",
    "LossClosure = Callable[[], float]\n",
    "OptLossClosure = Optional[LossClosure]\n",
    "Betas2 = Tuple[float, float]\n",
    "State = Dict[str, Any]\n",
    "OptFloat = Optional[float]\n",
    "Nus2 = Tuple[float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d14bbe53-3aa3-4333-aa91-38b03eebf9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "# from .types import OptFloat, OptLossClosure, Params\n",
    "\n",
    "\n",
    "def _matrix_power(matrix: torch.Tensor, power: float) -> torch.Tensor:\n",
    "    # use CPU for svd for speed up\n",
    "    device = matrix.device\n",
    "    # matrix = matrix.cpu()\n",
    "    u, s, v = torch.svd(matrix,)\n",
    "    return (u @ s.pow_(power).diag() @ v.t()).to(device)\n",
    "\n",
    "\n",
    "class Shampoo(Optimizer):\n",
    "    r\"\"\"Implements Shampoo Optimizer Algorithm.\n",
    "\n",
    "    It has been proposed in `Shampoo: Preconditioned Stochastic Tensor\n",
    "    Optimization`__.\n",
    "\n",
    "    Arguments:\n",
    "        params: iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr: learning rate (default: 1e-3)\n",
    "        momentum: momentum factor (default: 0)\n",
    "        weight_decay: weight decay (L2 penalty) (default: 0)\n",
    "        epsilon: epsilon added to each mat_gbar_j for numerical stability\n",
    "            (default: 1e-4)\n",
    "        update_freq: update frequency to compute inverse (default: 1)\n",
    "\n",
    "    Example:\n",
    "        >>> import torch_optimizer as optim\n",
    "        >>> optimizer = optim.Shampoo(model.parameters(), lr=0.01)\n",
    "        >>> optimizer.zero_grad()\n",
    "        >>> loss_fn(model(input), target).backward()\n",
    "        >>> optimizer.step()\n",
    "\n",
    "    __ https://arxiv.org/abs/1802.09568\n",
    "\n",
    "    Note:\n",
    "        Reference code: https://github.com/moskomule/shampoo.pytorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params: Params,\n",
    "        lr: float = 1e-1,\n",
    "        momentum: float = 0.0,\n",
    "        weight_decay: float = 0.0,\n",
    "        epsilon: float = 1e-4,\n",
    "        update_freq: int = 1,\n",
    "    ):\n",
    "        if lr <= 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\n",
    "                \"Invalid weight_decay value: {}\".format(weight_decay)\n",
    "            )\n",
    "        if epsilon < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if update_freq < 1:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay,\n",
    "            epsilon=epsilon,\n",
    "            update_freq=update_freq,\n",
    "        )\n",
    "        super(Shampoo, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure: OptLossClosure = None) -> OptFloat:\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure: A closure that reevaluates the model and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                order = grad.ndimension()\n",
    "                original_size = grad.size()\n",
    "                state = self.state[p]\n",
    "                momentum = group[\"momentum\"]\n",
    "                weight_decay = group[\"weight_decay\"]\n",
    "                if len(state) == 0:\n",
    "                    state[\"step\"] = 0\n",
    "                    if momentum > 0:\n",
    "                        state[\"momentum_buffer\"] = grad.clone()\n",
    "                    for dim_id, dim in enumerate(grad.size()):\n",
    "                        # precondition matrices\n",
    "                        state[\"precond_{}\".format(dim_id)] = group[\n",
    "                            \"epsilon\"\n",
    "                        ] * torch.eye(dim, out=grad.new(dim, dim))\n",
    "                        state[\n",
    "                            \"inv_precond_{dim_id}\".format(dim_id=dim_id)\n",
    "                        ] = grad.new(dim, dim).zero_()\n",
    "\n",
    "                if momentum > 0:\n",
    "                    grad.mul_(1 - momentum).add_(\n",
    "                        state[\"momentum_buffer\"], alpha=momentum\n",
    "                    )\n",
    "\n",
    "                if weight_decay > 0:\n",
    "                    grad.add_(p.data, alpha=group[\"weight_decay\"])\n",
    "\n",
    "                # See Algorithm 2 for detail\n",
    "                for dim_id, dim in enumerate(grad.size()):\n",
    "                    precond = state[\"precond_{}\".format(dim_id)]\n",
    "                    inv_precond = state[\"inv_precond_{}\".format(dim_id)]\n",
    "\n",
    "                    # mat_{dim_id}(grad)\n",
    "                    grad = grad.transpose_(0, dim_id).contiguous()\n",
    "                    transposed_size = grad.size()\n",
    "                    grad = grad.view(dim, -1)\n",
    "\n",
    "                    grad_t = grad.t()\n",
    "                    precond.add_(grad @ grad_t)\n",
    "                    if state[\"step\"] % group[\"update_freq\"] == 0:\n",
    "                        inv_precond.copy_(_matrix_power(precond, -1 / order))\n",
    "\n",
    "                    if dim_id == order - 1:\n",
    "                        # finally\n",
    "                        grad = grad_t @ inv_precond\n",
    "                        # grad: (-1, last_dim)\n",
    "                        grad = grad.view(original_size)\n",
    "                    else:\n",
    "                        # if not final\n",
    "                        grad = inv_precond @ grad\n",
    "                        # grad (dim, -1)\n",
    "                        grad = grad.view(transposed_size)\n",
    "\n",
    "                state[\"step\"] += 1\n",
    "                state[\"momentum_buffer\"] = grad\n",
    "                p.data.add_(grad, alpha=-group[\"lr\"])\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c9f24-55d7-4b45-b27e-b1dc3fb068c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder one_index_exp/Shampoo_20251006_200843\n",
      "[INFO] Writing config to one_index_exp/Shampoo_20251006_200843/config.txt\n",
      "[INFO] Starting 5 repetitions of Shampoo\n",
      "  Epoch 995/3000 ( 33.2%)\r"
     ]
    }
   ],
   "source": [
    "lrs = [0.01 ]\n",
    "batch_sizes = [512, ]\n",
    "\n",
    "N = 3000\n",
    "\n",
    "for lr in lrs:\n",
    "    for bs in batch_sizes:\n",
    "        opt_kwargs = {}\n",
    "        if lr is not None:\n",
    "            opt_kwargs['lr'] = lr\n",
    "\n",
    "        results = run_optimizer_experiment(\n",
    "            optimizer_cls   = Shampoo,\n",
    "            optimizer_kwargs = opt_kwargs,\n",
    "            batch_size      = bs,\n",
    "            num_repeats     = 5,\n",
    "            num_epochs      = N,\n",
    "            early_stop = True,\n",
    "            output_dir = \"one_index_exp\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a039117-ae17-49c5-8dc9-16662ce6a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
